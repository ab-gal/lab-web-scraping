{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e7a1ab8-2599-417d-9a65-25ef07f3a786",
   "metadata": {
    "id": "7e7a1ab8-2599-417d-9a65-25ef07f3a786"
   },
   "source": [
    "# Lab | Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8882fc-4815-4567-92fa-b4816358ba7d",
   "metadata": {
    "id": "ce8882fc-4815-4567-92fa-b4816358ba7d"
   },
   "source": [
    "Welcome to the \"Books to Scrape\" Web Scraping Adventure Lab!\n",
    "\n",
    "**Objective**\n",
    "\n",
    "In this lab, we will embark on a mission to unearth valuable insights from the data available on Books to Scrape, an online platform showcasing a wide variety of books. As data analyst, you have been tasked with scraping a specific subset of book data from Books to Scrape to assist publishing companies in understanding the landscape of highly-rated books across different genres. Your insights will help shape future book marketing strategies and publishing decisions.\n",
    "\n",
    "**Background**\n",
    "\n",
    "In a world where data has become the new currency, businesses are leveraging big data to make informed decisions that drive success and profitability. The publishing industry, much like others, utilizes data analytics to understand market trends, reader preferences, and the performance of books based on factors such as genre, author, and ratings. Books to Scrape serves as a rich source of such data, offering detailed information about a diverse range of books, making it an ideal platform for extracting insights to aid in informed decision-making within the literary world.\n",
    "\n",
    "**Task**\n",
    "\n",
    "Your task is to create a Python script using BeautifulSoup and pandas to scrape Books to Scrape book data, focusing on book ratings and genres. The script should be able to filter books with ratings above a certain threshold and in specific genres. Additionally, the script should structure the scraped data in a tabular format using pandas for further analysis.\n",
    "\n",
    "**Expected Outcome**\n",
    "\n",
    "A function named `scrape_books` that takes two parameters: `min_rating` and `max_price`. The function should scrape book data from the \"Books to Scrape\" website and return a `pandas` DataFrame with the following columns:\n",
    "\n",
    "**Expected Outcome**\n",
    "\n",
    "- A function named `scrape_books` that takes two parameters: `min_rating` and `max_price`.\n",
    "- The function should return a DataFrame with the following columns:\n",
    "  - **UPC**: The Universal Product Code (UPC) of the book.\n",
    "  - **Title**: The title of the book.\n",
    "  - **Price (£)**: The price of the book in pounds.\n",
    "  - **Rating**: The rating of the book (1-5 stars).\n",
    "  - **Genre**: The genre of the book.\n",
    "  - **Availability**: Whether the book is in stock or not.\n",
    "  - **Description**: A brief description or product description of the book (if available).\n",
    "  \n",
    "You will execute this script to scrape data for books with a minimum rating of `4.0 and above` and a maximum price of `£20`. \n",
    "\n",
    "Remember to experiment with different ratings and prices to ensure your code is versatile and can handle various searches effectively!\n",
    "\n",
    "**Resources**\n",
    "\n",
    "- [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Pandas Documentation](https://pandas.pydata.org/pandas-docs/stable/index.html)\n",
    "- [Books to Scrape](https://books.toscrape.com/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3519921d-5890-445b-9a33-934ed8ee378c",
   "metadata": {
    "id": "3519921d-5890-445b-9a33-934ed8ee378c"
   },
   "source": [
    "**Hint**\n",
    "\n",
    "Your first mission is to familiarize yourself with the **Books to Scrape** website. Navigate to [Books to Scrape](http://books.toscrape.com/) and explore the available books to understand their layout and structure. \n",
    "\n",
    "Next, think about how you can set parameters for your data extraction:\n",
    "\n",
    "- **Minimum Rating**: Focus on books with a rating of 4.0 and above.\n",
    "- **Maximum Price**: Filter for books priced up to £20.\n",
    "\n",
    "After reviewing the site, you can construct a plan for scraping relevant data. Pay attention to the details displayed for each book, including the title, price, rating, and availability. This will help you identify the correct HTML elements to target with your scraping script.\n",
    "\n",
    "Make sure to build your scraping URL and logic based on the patterns you observe in the HTML structure of the book listings!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a83a0d-a742-49f6-985e-e27887cbf922",
   "metadata": {
    "id": "25a83a0d-a742-49f6-985e-e27887cbf922"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Best of luck! Immerse yourself in the world of books, and may the data be with you!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b75cf0d-9afa-4eec-a9e2-befeac68b2a0",
   "metadata": {
    "id": "7b75cf0d-9afa-4eec-a9e2-befeac68b2a0"
   },
   "source": [
    "**Important Note**:\n",
    "\n",
    "In the fast-changing online world, websites often update and change their structures. When you try this lab, the **Books to Scrape** website might differ from what you expect.\n",
    "\n",
    "If you encounter issues due to these changes, like new rules or obstacles preventing data extraction, don’t worry! Get creative.\n",
    "\n",
    "You can choose another website that interests you and is suitable for scraping data. Options like Wikipedia, The New York Times, or even library databases are great alternatives. The main goal remains the same: extract useful data and enhance your web scraping skills while exploring a source of information you enjoy. This is your opportunity to practice and adapt to different web environments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bcb257a-5b23-4a80-9a34-841288c769a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# websites=[f'https://books.toscrape.com/catalogue/page-{pag}.html' for pag in range(1,6)]\n",
    "# websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69f19fb2-f93f-4115-92b2-d40bfcb51876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_books(min_rating, max_price, number_pages_to_scrape=51):\n",
    "    websites=[f'https://books.toscrape.com/catalogue/page-{pag}.html' for pag in range(1, number_pages_to_scrape)]\n",
    "    UPC_l=[]\n",
    "    title_l=[]\n",
    "    price_l=[]\n",
    "    rating_l=[]\n",
    "    genre_l=[]\n",
    "    availability_l=[]\n",
    "    description_l=[]\n",
    "    for website in websites:\n",
    "        pages_menu = requests.get(website)\n",
    "        #pages_menu.content\n",
    "        pages = BeautifulSoup(pages_menu.content, 'html.parser')\n",
    "        pages=pages.find('ol', class_='row')\n",
    "        pages=pages.find_all('a')\n",
    "        books_links_list=set([page.get('href') for page in pages])\n",
    "        books_links=['https://books.toscrape.com/catalogue/'+ link for link in books_links_list]\n",
    "        \n",
    "        for url in books_links:\n",
    "            response = requests.get(url)\n",
    "            response.content\n",
    "            soup = BeautifulSoup(response.content, 'html.parser') \n",
    "    \n",
    "            price=soup.find(string='Price (incl. tax)').find_next('td').text.strip()\n",
    "            price=price.replace('£', '')\n",
    "            price=float(price)\n",
    "            # print(f'price {price}')\n",
    "            \n",
    "            rating_search=soup.find('p', class_='star-rating')\n",
    "            rating_corelation={'One': 1,\n",
    "                               'Two': 2,\n",
    "                               'Three': 3,\n",
    "                               'Four': 4,\n",
    "                               'Five': 5}\n",
    "            rating_2=rating_search.get('class')[1].strip()\n",
    "            rating=rating_corelation.get(rating_2)\n",
    "            rating=int(rating)\n",
    "            # print(f'rating {rating}')\n",
    "            \n",
    "            if price<=max_price and rating>=min_rating:\n",
    "                price_l.append(price)\n",
    "                rating_l.append(rating)\n",
    "                \n",
    "                UPC=soup.find(class_=\"table table-striped\").find_next(string='UPC').find_next('td').text.strip()\n",
    "                UPC_l.append(UPC)\n",
    "        \n",
    "                title=soup.find(class_=\"col-sm-6 product_main\").find_next('h1').text.strip()\n",
    "                title_l.append(title)\n",
    "        \n",
    "                genre=soup.find('ul', class_='breadcrumb').find_next('li').find_next('li').find_next('li').text.strip()\n",
    "                genre_l.append(genre)\n",
    "            \n",
    "                availability=soup.find(class_='table table-striped').find_next('th', string='Availability').find_next('td').text\n",
    "                availability=int(availability.split()[2].replace('(', ''))\n",
    "                availability_l.append(availability)\n",
    "        \n",
    "                description=soup.find('div', class_='sub-header').find_next('p').text\n",
    "                description_l.append(description)\n",
    "                \n",
    "    df=pd.DataFrame({'upc': UPC_l,\n",
    "                     'title': title_l,\n",
    "                     'price': price_l,\n",
    "                     'rating': rating_l,\n",
    "                     'genre': genre_l,\n",
    "                     'availability': availability_l,\n",
    "                     'description': description_l })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0fc2168-dded-47bb-8087-e55c46cfd1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>upc</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "      <th>genre</th>\n",
       "      <th>availability</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ce6396b0f23f6ecc</td>\n",
       "      <td>Set Me Free</td>\n",
       "      <td>17.46</td>\n",
       "      <td>5</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>19</td>\n",
       "      <td>Aaron Ledbetter’s future had been planned out ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6be3beb0793a53e7</td>\n",
       "      <td>Sophie's World</td>\n",
       "      <td>15.94</td>\n",
       "      <td>5</td>\n",
       "      <td>Philosophy</td>\n",
       "      <td>18</td>\n",
       "      <td>A page-turning novel that is also an explorati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6258a1f6a6dcfe50</td>\n",
       "      <td>The Four Agreements: A Practical Guide to Pers...</td>\n",
       "      <td>17.66</td>\n",
       "      <td>5</td>\n",
       "      <td>Spirituality</td>\n",
       "      <td>18</td>\n",
       "      <td>In The Four Agreements, don Miguel Ruiz reveal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51653ef291ab7ddc</td>\n",
       "      <td>This One Summer</td>\n",
       "      <td>19.49</td>\n",
       "      <td>4</td>\n",
       "      <td>Sequential Art</td>\n",
       "      <td>16</td>\n",
       "      <td>Every summer, Rose goes with her mom and dad t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>709822d0b5bcb7f4</td>\n",
       "      <td>Thirst</td>\n",
       "      <td>17.27</td>\n",
       "      <td>5</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>16</td>\n",
       "      <td>On a searing summer Friday, Eddie Chapman has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>657fe5ead67a7767</td>\n",
       "      <td>Untitled Collection: Sabbath Poems 2014</td>\n",
       "      <td>14.27</td>\n",
       "      <td>4</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>16</td>\n",
       "      <td>More than thirty-five years ago, when the weat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>72f9d5be3472d34e</td>\n",
       "      <td>Mama Tried: Traditional Italian Cooking for th...</td>\n",
       "      <td>14.02</td>\n",
       "      <td>4</td>\n",
       "      <td>Food and Drink</td>\n",
       "      <td>16</td>\n",
       "      <td>Cecilia Granata grew up cooking with her famil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0e691eda369f4e09</td>\n",
       "      <td>Princess Between Worlds (Wide-Awake Princess #5)</td>\n",
       "      <td>13.34</td>\n",
       "      <td>5</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>16</td>\n",
       "      <td>Just as Annie and Liam are busy making plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>889139b8e9c4cb36</td>\n",
       "      <td>Outcast, Vol. 1: A Darkness Surrounds Him (Out...</td>\n",
       "      <td>15.44</td>\n",
       "      <td>4</td>\n",
       "      <td>Sequential Art</td>\n",
       "      <td>16</td>\n",
       "      <td>NEW HORROR SERIES FROM THE WALKING DEAD CREATO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0fa6dceead7ce47a</td>\n",
       "      <td>Princess Jellyfish 2-in-1 Omnibus, Vol. 01 (Pr...</td>\n",
       "      <td>13.61</td>\n",
       "      <td>5</td>\n",
       "      <td>Sequential Art</td>\n",
       "      <td>16</td>\n",
       "      <td>THE LONG-AWAITED STORY OF FANGIRLS TAKING ON T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                upc                                              title  price  \\\n",
       "0  ce6396b0f23f6ecc                                        Set Me Free  17.46   \n",
       "1  6be3beb0793a53e7                                     Sophie's World  15.94   \n",
       "2  6258a1f6a6dcfe50  The Four Agreements: A Practical Guide to Pers...  17.66   \n",
       "3  51653ef291ab7ddc                                    This One Summer  19.49   \n",
       "4  709822d0b5bcb7f4                                             Thirst  17.27   \n",
       "5  657fe5ead67a7767            Untitled Collection: Sabbath Poems 2014  14.27   \n",
       "6  72f9d5be3472d34e  Mama Tried: Traditional Italian Cooking for th...  14.02   \n",
       "7  0e691eda369f4e09   Princess Between Worlds (Wide-Awake Princess #5)  13.34   \n",
       "8  889139b8e9c4cb36  Outcast, Vol. 1: A Darkness Surrounds Him (Out...  15.44   \n",
       "9  0fa6dceead7ce47a  Princess Jellyfish 2-in-1 Omnibus, Vol. 01 (Pr...  13.61   \n",
       "\n",
       "   rating           genre  availability  \\\n",
       "0       5     Young Adult            19   \n",
       "1       5      Philosophy            18   \n",
       "2       5    Spirituality            18   \n",
       "3       4  Sequential Art            16   \n",
       "4       5         Fiction            16   \n",
       "5       4          Poetry            16   \n",
       "6       4  Food and Drink            16   \n",
       "7       5         Fantasy            16   \n",
       "8       4  Sequential Art            16   \n",
       "9       5  Sequential Art            16   \n",
       "\n",
       "                                         description  \n",
       "0  Aaron Ledbetter’s future had been planned out ...  \n",
       "1  A page-turning novel that is also an explorati...  \n",
       "2  In The Four Agreements, don Miguel Ruiz reveal...  \n",
       "3  Every summer, Rose goes with her mom and dad t...  \n",
       "4  On a searing summer Friday, Eddie Chapman has ...  \n",
       "5  More than thirty-five years ago, when the weat...  \n",
       "6  Cecilia Granata grew up cooking with her famil...  \n",
       "7  Just as Annie and Liam are busy making plans t...  \n",
       "8  NEW HORROR SERIES FROM THE WALKING DEAD CREATO...  \n",
       "9  THE LONG-AWAITED STORY OF FANGIRLS TAKING ON T...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_books(4, 20, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79c86e0d-0283-4be8-be8e-e74fcedf452d",
   "metadata": {
    "id": "40359eee-9cd7-4884-bfa4-83344c222305"
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# response = requests.get('https://books.toscrape.com/catalogue/the-requiem-red_995/index.html')\n",
    "# response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72b4d914-ba5b-494f-9ad6-cf269d89e792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3864c8-be15-4a03-887b-19f7ef926dc0",
   "metadata": {},
   "source": [
    "UPC: The Universal Product Code (UPC) of the book.\n",
    "Title: The title of the book.\n",
    "Price (£): The price of the book in pounds.\n",
    "Rating: The rating of the book (1-5 stars).\n",
    "Genre: The genre of the book.\n",
    "Availability: Whether the book is in stock or not.\n",
    "Description: A brief description or product description of the book (if available)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246563dd-ef44-4457-b1c0-b28ef86f002d",
   "metadata": {},
   "source": [
    "def get_attributes(url):\n",
    "    import pandas as pd\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    response = requests.get(url)\n",
    "    response.content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "def UPC(soup):\n",
    "    UPC=soup.find(class_=\"table table-striped\").find_next(text='UPC').find_next('td').text.strip()\n",
    "    return UPC\n",
    "def title(soup):\n",
    "    title=soup.find(class_=\"col-sm-6 product_main\").find_next('h1').text.strip()\n",
    "    return title\n",
    "def price(soup):\n",
    "    price=soup.find(text='Price (incl. tax)').find_next('td').text.strip()\n",
    "    price=price.replace('£', '')\n",
    "    price=float(price)\n",
    "    return price\n",
    "def rating(soup):\n",
    "    rating_search=soup.find('p', class_='star-rating')\n",
    "    rating_corelation={'One': 1,\n",
    "                   'Two': 2,\n",
    "                   'Three': 3,\n",
    "                   'Four': 4,\n",
    "                   'Five': 5}\n",
    "    rating_2=rating_search.get('class')[1].strip()\n",
    "    rating=rating_corelation.get(rating_2)\n",
    "    int(rating)\n",
    "def genre(soup):\n",
    "    genre=soup.find('ul', class_='breadcrumb').find_next('li').find_next('li').find_next('li').text.strip()\n",
    "    return genre\n",
    "def title(soup):\n",
    "    availability=soup.find(class_='table table-striped').find_next('th', string='Availability').find_next('td').text\n",
    "    return int(availability.split()[2].replace('(', ''))\n",
    "def description(soup):\n",
    "    description=soup.find('div', class_='sub-header').find_next('p').text\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9054eff9-17f3-465f-b748-5b8974eb45e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPC=soup.find(class_=\"table table-striped\").find_next(text='UPC').find_next('td').text.strip()\n",
    "# UPC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d06400-d882-45ab-a135-ffaa86898f6f",
   "metadata": {},
   "source": [
    "UPC_header = soup.find('th', string='UPC')\n",
    "\n",
    "if UPC_header:\n",
    "    UPC_data_cell = UPC_header.find_next_sibling('td')\n",
    "    UPC = UPC_data_cell.text.strip()\n",
    "    # Now UPC is safely extracted\n",
    "else:\n",
    "    # Handle the case where the UPC header is not found\n",
    "    UPC = None\n",
    "UPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b63bdd1e-7d29-49cd-807c-51962020cace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title=soup.find(class_=\"col-sm-6 product_main\").find_next('h1').text.strip()\n",
    "# title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38aa4091-1c21-4670-bdfe-2b52404e606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price=soup.find(text='Price (incl. tax)').find_next('td').text.strip()\n",
    "# price=price.replace('£', '')\n",
    "# price=float(price)\n",
    "# price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a5705e3-cac4-44a8-80ee-cf4d34dfa761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating_search=soup.find('p', class_='star-rating')\n",
    "# rating_corelation={'One': 1,\n",
    "#                    'Two': 2,\n",
    "#                    'Three': 3,\n",
    "#                    'Four': 4,\n",
    "#                    'Five': 5}\n",
    "# rating_2=rating_search.get('class')[1].strip()\n",
    "# rating=rating_corelation.get(rating_2)\n",
    "# int(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31572631-6974-4583-bad0-7bd472317eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# genre_search=soup.find('ul', class_='breadcrumb').find_next('li').find_next('li').find_next('li').text.strip()\n",
    "# genre_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13e3e0e4-d377-46aa-b62d-48e15ae73bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# genre_search=soup.find('a', string='Books').find_next('li').text.strip()\n",
    "# genre_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8335b79a-02c5-4036-8d61-17a734212c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# availability=soup.find(class_='table table-striped').find_next('th', string='Availability').find_next('td').text\n",
    "# int(availability.split()[2].replace('(', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5faf636c-e38a-478b-8194-0a6a381e0d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# description=soup.find('div', class_='sub-header').find_next('p').text\n",
    "# description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd45ef12-9a57-4685-aca4-3a3f33e36c13",
   "metadata": {},
   "source": [
    "websites=[f'https://books.toscrape.com/catalogue/page-{pag}.html' for pag in range(1,51)]\n",
    "websites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d15204f-3dc0-4977-bb55-a6dc14cf2b13",
   "metadata": {},
   "source": [
    "pages_menu = requests.get('https://books.toscrape.com')\n",
    "pages_menu.content\n",
    "pages = BeautifulSoup(pages_menu.content, 'html.parser')\n",
    "pages=pages.find('ol', class_='row')\n",
    "pages=pages.find_all('a')\n",
    "books_links_list=[page.get('href') for page in pages]\n",
    "books_links=['https://books.toscrape.com/'+ link for link in books_links_list]\n",
    "books_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e448abde-14b4-4de6-8152-34249497a5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# websites=[f'https://books.toscrape.com/catalogue/page-{pag}.html' for pag in range(1,51)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eda5332-4353-444b-a28c-20e0e4142169",
   "metadata": {},
   "source": [
    "def get_attributes(websites):\n",
    "    UPC_l=[]\n",
    "    title_l=[]\n",
    "    price_l=[]\n",
    "    rating_l=[]\n",
    "    genre_l=[]\n",
    "    availability_l=[]\n",
    "    description_l=[]\n",
    "    for website in websites:\n",
    "        pages_menu = requests.get(website)\n",
    "        pages_menu.content\n",
    "        pages = BeautifulSoup(pages_menu.content, 'html.parser')\n",
    "        pages=pages.find('ol', class_='row')\n",
    "        pages=pages.find_all('a')\n",
    "        books_links_list=[page.get('href') for page in pages]\n",
    "        books_links=['https://books.toscrape.com/'+ link for link in books_links_list]\n",
    "        \n",
    "        for url in books_links:\n",
    "            response = requests.get(url)\n",
    "            response.content\n",
    "            soup = BeautifulSoup(response.content, 'html.parser') \n",
    "            \n",
    "            UPC=soup.find(class_=\"table table-striped\").find_next(text='UPC').find_next('td').text.strip()\n",
    "            UPC_l.append(UPC)\n",
    "\n",
    "            title=soup.find(class_=\"col-sm-6 product_main\").find_next('h1').text.strip()\n",
    "            title_l.append(title)\n",
    "\n",
    "            price=soup.find(text='Price (incl. tax)').find_next('td').text.strip()\n",
    "            price=price.replace('£', '')\n",
    "            price=float(price)\n",
    "            price_l.append(price)\n",
    "\n",
    "            rating_search=soup.find('p', class_='star-rating')\n",
    "            rating_corelation={'One': 1,\n",
    "                           'Two': 2,\n",
    "                           'Three': 3,\n",
    "                           'Four': 4,\n",
    "                           'Five': 5}\n",
    "            rating_2=rating_search.get('class')[1].strip()\n",
    "            rating=rating_corelation.get(rating_2)\n",
    "            int(rating)\n",
    "            rating.append(rating)\n",
    "\n",
    "            genre=soup.find('ul', class_='breadcrumb').find_next('li').find_next('li').find_next('li').text.strip()\n",
    "            genre_l.append(genre)\n",
    "\n",
    "            availability=soup.find(class_='table table-striped').find_next('th', string='Availability').find_next('td').text\n",
    "            availability=int(availability.split()[2].replace('(', ''))\n",
    "            availability_l.append(availability)\n",
    "\n",
    "            description=soup.find('div', class_='sub-header').find_next('p').text\n",
    "            description_l.append(description)\n",
    "    df=pd.DataFrame({'upc': UPC_l,\n",
    "                     'title': title_l,\n",
    "                     'price': price_l,\n",
    "                     'rating': rating_l,\n",
    "                     'genre': genre_l,\n",
    "                     'availability': availability_l,\n",
    "                     'description': description_l })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1101f125-f55a-4e25-ac95-bd23aaf966d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# websites=[f'https://books.toscrape.com/catalogue/page-{pag}.html' for pag in range(1,6)]\n",
    "# websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e61c2efc-470a-4390-b1af-54f09eae5ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPC_l=[]\n",
    "# title_l=[]\n",
    "# price_l=[]\n",
    "# rating_l=[]\n",
    "# genre_l=[]\n",
    "# availability_l=[]\n",
    "# description_l=[]\n",
    "# for website in websites:\n",
    "#     pages_menu = requests.get(website)\n",
    "#     #pages_menu.content\n",
    "#     pages = BeautifulSoup(pages_menu.content, 'html.parser')\n",
    "#     pages=pages.find('ol', class_='row')\n",
    "#     pages=pages.find_all('a')\n",
    "#     books_links_list=set([page.get('href') for page in pages])\n",
    "#     books_links=['https://books.toscrape.com/catalogue/'+ link for link in books_links_list]\n",
    "    \n",
    "#     for url in books_links:\n",
    "#         response = requests.get(url)\n",
    "#         response.content\n",
    "#         soup = BeautifulSoup(response.content, 'html.parser') \n",
    "        \n",
    "        \n",
    "#         UPC=soup.find(class_=\"table table-striped\").find_next(string='UPC').find_next('td').text.strip()\n",
    "#         UPC_l.append(UPC)\n",
    "\n",
    "#         title=soup.find(class_=\"col-sm-6 product_main\").find_next('h1').text.strip()\n",
    "#         title_l.append(title)\n",
    "\n",
    "#         price=soup.find(string='Price (incl. tax)').find_next('td').text.strip()\n",
    "#         price=price.replace('£', '')\n",
    "#         price=float(price)\n",
    "#         price_l.append(price)\n",
    "\n",
    "#         genre=soup.find('ul', class_='breadcrumb').find_next('li').find_next('li').find_next('li').text.strip()\n",
    "#         genre_l.append(genre)\n",
    "\n",
    "#         rating_search=soup.find('p', class_='star-rating')\n",
    "#         rating_corelation={'One': 1,\n",
    "#                            'Two': 2,\n",
    "#                            'Three': 3,\n",
    "#                            'Four': 4,\n",
    "#                            'Five': 5}\n",
    "#         rating_2=rating_search.get('class')[1].strip()\n",
    "#         rating=rating_corelation.get(rating_2)\n",
    "#         rating=int(rating)\n",
    "#         rating_l.append(rating)\n",
    "\n",
    "#         availability=soup.find(class_='table table-striped').find_next('th', string='Availability').find_next('td').text\n",
    "#         availability=int(availability.split()[2].replace('(', ''))\n",
    "#         availability_l.append(availability)\n",
    "\n",
    "#         description=soup.find('div', class_='sub-header').find_next('p').text\n",
    "#         description_l.append(description)\n",
    "# df=pd.DataFrame({'upc': UPC_l,\n",
    "#                  'title': title_l,\n",
    "#                  'price': price_l,\n",
    "#                  'rating': rating_l,\n",
    "#                  'genre': genre_l,\n",
    "#                  'availability': availability_l,\n",
    "#                  'description': description_l })\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8c83d17-d32b-4eb0-8a19-4268a40e94c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPC_l=[]\n",
    "# title_l=[]\n",
    "# price_l=[]\n",
    "# rating_l=[]\n",
    "# genre_l=[]\n",
    "# availability_l=[]\n",
    "# description_l=[]\n",
    "# for website in websites:\n",
    "#     pages_menu = requests.get(website)\n",
    "#     #pages_menu.content\n",
    "#     pages = BeautifulSoup(pages_menu.content, 'html.parser')\n",
    "#     pages=pages.find('ol', class_='row')\n",
    "#     pages=pages.find_all('a')\n",
    "#     books_links_list=set([page.get('href') for page in pages])\n",
    "#     books_links=['https://books.toscrape.com/catalogue/'+ link for link in books_links_list]\n",
    "    \n",
    "#     for url in books_links:\n",
    "#         response = requests.get(url)\n",
    "#         response.content\n",
    "#         soup = BeautifulSoup(response.content, 'html.parser') \n",
    "\n",
    "#         price=soup.find(string='Price (incl. tax)').find_next('td').text.strip()\n",
    "#         price=price.replace('£', '')\n",
    "#         price=float(price)\n",
    "#         # print(f'price {price}')\n",
    "        \n",
    "#         rating_search=soup.find('p', class_='star-rating')\n",
    "#         rating_corelation={'One': 1,\n",
    "#                            'Two': 2,\n",
    "#                            'Three': 3,\n",
    "#                            'Four': 4,\n",
    "#                            'Five': 5}\n",
    "#         rating_2=rating_search.get('class')[1].strip()\n",
    "#         rating=rating_corelation.get(rating_2)\n",
    "#         rating=int(rating)\n",
    "#         # print(f'rating {rating}')\n",
    "        \n",
    "#         if price<=20 and rating>=4:\n",
    "#             price_l.append(price)\n",
    "#             rating_l.append(rating)\n",
    "            \n",
    "#             UPC=soup.find(class_=\"table table-striped\").find_next(string='UPC').find_next('td').text.strip()\n",
    "#             UPC_l.append(UPC)\n",
    "    \n",
    "#             title=soup.find(class_=\"col-sm-6 product_main\").find_next('h1').text.strip()\n",
    "#             title_l.append(title)\n",
    "    \n",
    "#             genre=soup.find('ul', class_='breadcrumb').find_next('li').find_next('li').find_next('li').text.strip()\n",
    "#             genre_l.append(genre)\n",
    "        \n",
    "#             availability=soup.find(class_='table table-striped').find_next('th', string='Availability').find_next('td').text\n",
    "#             availability=int(availability.split()[2].replace('(', ''))\n",
    "#             availability_l.append(availability)\n",
    "    \n",
    "#             description=soup.find('div', class_='sub-header').find_next('p').text\n",
    "#             description_l.append(description)\n",
    "            \n",
    "# df=pd.DataFrame({'upc': UPC_l,\n",
    "#                  'title': title_l,\n",
    "#                  'price': price_l,\n",
    "#                  'rating': rating_l,\n",
    "#                  'genre': genre_l,\n",
    "#                  'availability': availability_l,\n",
    "#                  'description': description_l })\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49dd47a-e174-4337-8cde-d55e7530aaf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5840f514-0781-4c37-88ed-168c201f0175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(UPC_l, title_l, price_l, rating_l, genre_l, availability_l, description_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13869b83-0129-47b4-93f4-f6db57a4651c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPC_l\n",
    "# title_l\n",
    "# price_l\n",
    "# rating_l\n",
    "# # genre_l\n",
    "# # availability_l\n",
    "# # description_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee05f29e-e39a-4991-abfe-6de12b326c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.DataFrame({'upc': UPC_l,\n",
    "#                  'title': title_l,\n",
    "#                  'price': price_l,\n",
    "#                  'rating': rating_l,\n",
    "#                  'genre': genre_l,\n",
    "#                  'availability': availability_l,\n",
    "#                  'description': description_l })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b017747d-03a8-40a9-a93e-df48fd1851b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "634de8aa-4171-4a31-a89e-a9964a004823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages_menu = requests.get('https://books.toscrape.com/catalogue/page-1.html')\n",
    "# #pages_menu.content\n",
    "# pages = BeautifulSoup(pages_menu.content, 'html.parser')\n",
    "# pages=pages.find('ol', class_='row')\n",
    "# pages=pages.find_all('a')\n",
    "# books_links_list=set([page.get('href') for page in pages])\n",
    "# books_links=['https://books.toscrape.com/catalogue/'+ link for link in books_links_list]\n",
    "# books_links\n",
    "# UPC=soup.find(class_=\"table table-striped\").find_next(string='UPC').find_next('td').text.strip()\n",
    "# UPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed0619a3-1110-44ca-8154-5354a26983d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages=pages.find('ol', class_='row')\n",
    "# pages_2=pages.find_all('a')\n",
    "# #books_links_list=[page.get('href') for page in pages]\n",
    "# books_links_list=[page.get('href') for page in pages_2]\n",
    "# books_links_set=set((books_links_list))\n",
    "# books_links=['https://books.toscrape.com/'+ link for link in books_links_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0eae0e25-3422-4f6a-8811-cf551cbee85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages=pages.find('ol', class_='row')\n",
    "# pages=pages.find_all('li')\n",
    "# books_links_list=[page.get('href') for page in pages]\n",
    "# books_links=['https://books.toscrape.com/'+ link for link in books_links_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75117b0-136f-4cce-bb59-e129136f7e91",
   "metadata": {},
   "source": [
    "# 1. Find the parent table\n",
    "table = soup.find('table', class_='table table-striped')\n",
    "\n",
    "# 2. Check if the table exists\n",
    "if table:\n",
    "    # 3. Find the header containing the specific text (using string= is safer)\n",
    "    upc_header = table.find('th', string='UPC')\n",
    "    \n",
    "    # 4. Check if the UPC header was found\n",
    "    if upc_header:\n",
    "        # 5. Find the next sibling data cell and extract text\n",
    "        upc_data_cell = upc_header.find_next_sibling('td')\n",
    "        UPC = upc_data_cell.text.strip()\n",
    "    else:\n",
    "        print(\"UPC header not found in the table.\")\n",
    "        UPC = None # Set to None or empty string if not found\n",
    "else:\n",
    "    print(\"Product Information table not found on the page.\")\n",
    "    UPC = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a68f0b8-61e8-4702-a175-436df0c1e2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8878966-cf11-4e35-8c3b-73799cafd7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2f056b-cf1e-47a3-8de6-cece7404fdac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae3a4f2-2dd0-45e1-89c4-4874edaee427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
